INFO:Dialogue:Starting the dialogue
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json HTTP/11" 401 0
INFO:Dialogue:Starting the dialogue
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json HTTP/11" 401 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/generation_config.json HTTP/11" 401 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/tokenizer_config.json HTTP/11" 401 0
INFO:Dialogue:History: assistant: Hi, I am your wine assistant. How can I help you?
user: i would like to have some deatils about a wine. It's a red one
INFO:Dialogue:Intents: ['general_info', 'wine_details']
INFO:Dialogue:List intents: ['general_info', 'wine_details']
INFO:Dialogue:NLU output: {'intent': 'general_info'}
INFO:Dialogue:general_info
DEBUG:Dialogue:DM input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>

You are the Dialogue Manager of a wine bot assistent.
Given the output of the NLU component, you should ONLY generate the next best action from this list: 
- request_info(slot), if a slot value is missing (null)
- goal_assistant(intent), if the intent is equal to out_of_domain
- repeat(slot), if the system needs clarification on a slot value
- confermation(intent), if all slots have been filled
You need to write the name of the action with also the correspondings parameters.
Return ONLY the next best action! Nothing more!<|eot_id|><|start_header_id|>user<|end_header_id|>

{'intent': 'general_info'}<|eot_id|><|start_header_id|>assistant<|end_header_id|>
DEBUG:Dialogue:DM output: request_info()
INFO:Dialogue:Action: request_info, Argument: 
INFO:Dialogue:NLG: <|begin_of_text|><|start_header_id|>system<|end_header_id|>

You are the NLG component of a wine bot assistent: you must be very polite.
Given the next best action classified by the Dialogue Manager (DM), you should only generate a lexicalized response for the user.
The response has to match the next best action of the DM.
Possible next best actions are:

- goal_assistant(intent): generate an appropriate message with the domain of the bot
- repeat(slot): generate a message to ask the user to repeat the information
- confermation(intent): generate an appropriate confirmation message for the user intentDO NOT give suggestions! Return ONLY the message to the user!<|eot_id|><|start_header_id|>user<|end_header_id|>

request_info()
assistant: Hi, I am your wine assistant. How can I help you?
user: i would like to have some deatils about a wine. It's a red one<|eot_id|><|start_header_id|>assistant<|end_header_id|>
INFO:Dialogue:Starting the dialogue
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json HTTP/11" 401 0
INFO:Dialogue:Starting the dialogue
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json HTTP/11" 401 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/generation_config.json HTTP/11" 401 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/tokenizer_config.json HTTP/11" 401 0
INFO:Dialogue:Starting the dialogue
DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json HTTP/11" 401 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/generation_config.json HTTP/11" 401 0
DEBUG:urllib3.connectionpool:https://huggingface.co:443 "HEAD /meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/tokenizer_config.json HTTP/11" 401 0
